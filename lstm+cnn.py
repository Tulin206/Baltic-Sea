# -*- coding: utf-8 -*-
"""LSTM+CNN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1M8BnxePyMaEg8NSFbyyQrYp7GjVbn1i_
"""
import os
import numpy as np
import matplotlib
import matplotlib.pyplot as plt
from matplotlib.animation import FuncAnimation
from IPython.display import HTML

import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Conv2D, Reshape, TimeDistributed, LSTM, Dense, Flatten
from tensorflow.keras.optimizers import Adam
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_percentage_error, explained_variance_score
from tensorflow.keras.callbacks import EarlyStopping

print("Num GPUs Available: ", len(tf.config.list_physical_devices('GPU')))

# Allow memory growth for GPUs to prevent TensorFlow from allocating all memory upfront
#physical_devices = tf.config.list_physical_devices('GPU')
#tf.config.experimental.set_memory_growth(physical_devices[0], True)

# load data
data = np.load("C:/Users/Tim/Desktop/ISRAT/RostockUniversity/data.npz")
train = data["train"] # Is creating validation set (hyperparameter tuning, model selection) necessary? If so, how?
test = data["test"]

mask = data["mask"] # mask of land area (filled with nans)

# the shape is (t, c, w, h) -> (time, channel [temperature, salinity], width, height)
# nan values are not of interest (land masses in this case)
# each time step is 6 hours
print(train.shape)

print(train.shape[0])

print(mask.shape)

# Create directories if they don't exist
os.makedirs("train", exist_ok=True)
os.makedirs("test", exist_ok=True)

# Save data to respective directories
np.save("train/data.npy", train)
np.save("test/data.npy", test)

# Optionally, save the mask (if needed for preprocessing)
np.save("train/mask.npy", mask)
np.save("test/mask.npy", mask)

print("Data split and saved!")

# Apply the mask to temperature and salinity channels separately
# Mask should be broadcasted across the time dimension
temperature_data = train[:, 0, :, :]  # Temperature channel
print("temperature_data shape:", temperature_data.shape)
salinity_data = train[:, 1, :, :]     # Salinity channel
print("salinity_data shape:", salinity_data.shape)

# Apply mask: Set land areas (masked) to NaN
temperature_data_ocean = np.where(mask == 1, np.nan, temperature_data)
print("temperature_data_ocean shape:", temperature_data_ocean.shape)
salinity_data_ocean = np.where(mask == 1, np.nan, salinity_data)
print("salinity_data_ocean shape:", salinity_data_ocean.shape)

# Flatten and remove NaNs to focus only on ocean data
temperature_data_non_nan = temperature_data_ocean[~np.isnan(temperature_data_ocean)]
print("temperature_data_non_nan shape:", temperature_data_non_nan.shape)
salinity_data_non_nan = salinity_data_ocean[~np.isnan(salinity_data_ocean)]
print("salinity_data_non_nan shape:", salinity_data_non_nan.shape)

# Check basic statistics for temperature and salinity in ocean areas
print("\nTemperature Data (Ocean Areas):")
print(f"  Min: {temperature_data_non_nan.min()}")
print(f"  Max: {temperature_data_non_nan.max()}")
print(f"  Mean: {temperature_data_non_nan.mean()}")
print(f"  Std Dev: {temperature_data_non_nan.std()}")

print("\nSalinity Data (Ocean Areas):")
print(f"  Min: {salinity_data_non_nan.min()}")
print(f"  Max: {salinity_data_non_nan.max()}")
print(f"  Mean: {salinity_data_non_nan.mean()}")
print(f"  Std Dev: {salinity_data_non_nan.std()}")

# The shape is (t, c, w, h) -> (time, channel [temperature, salinity], width, height)
# Each time step is 6 hours, nan values represent land masses.

# Define look-back and look-ahead window sizes, this is fixed for the task
look_back = int(7 * 24 / 6)  # 28 time steps (7 days) -> our input
look_ahead = 14 * 24 // 6  # 56 time steps (14 days) -> our prediction window
step_size = 24 // 6 # daily step size

def create_sample_pairs(subset, look_back: int, look_ahead: int, step_size: int):
    # Initialize lists to hold input-output pairs
    X, y = [], []

    # Loop over time series to create samples
    for i in range(look_back, subset.shape[0] - look_ahead, step_size):
        # Extract input sequence (look-back window) and output (look-ahead window)
        X_sample = subset[i - look_back: i, :, :, :]
        y_sample = subset[i + look_ahead, :, :, :]

        # Append to training data lists
        X.append(X_sample)
        y.append(y_sample)

    # Convert lists to numpy arrays
    X = np.array(X)
    y = np.array(y)

    return X, y

# Create sample pairs for both training and validation sets
sample, label = create_sample_pairs(train, look_back, look_ahead, step_size)
print("sample shape:", sample.shape)  # Should be (num_samples, look_back, c, w, h)
print("label shape:", label.shape)  # Should be (num_samples, c, w, h)

'''
# Sample selection
random_i = 42  # Select a specific time series sample
look_back_data = sample[random_i, :, 1, :, :]  # Look-back data (time steps, width, height)

# Set up the figure
fig, ax = plt.subplots(figsize=(8, 6))
img = ax.imshow(look_back_data[0], cmap='coolwarm', vmin=np.nanmin(look_back_data), vmax=np.nanmax(look_back_data))
fig.colorbar(img, ax=ax, label="Temperature")
ax.set_title(f"Temperature Over Time at Sample {random_i}")
ax.set_xlabel("Width")
ax.set_ylabel("Height")

# Animation update function
def update_frame(t):
    img.set_data(look_back_data[t])
    # Update the title to show the current time step
    ax.set_title(f"Temperature at Time Step {t} (6-hour intervals)")

# Create animation
ani = FuncAnimation(fig, update_frame, frames=look_back_data.shape[0], interval=200)

# Save the animation as an HTML5 video
ani.save('temperature_animation.mp4', writer="ffmpeg")

# Display the video in JupyterLab
plt.close(fig)  # Close the figure to avoid extra static plot output
HTML('<video controls src="temperature_animation.mp4" width="80%"></video>')
'''
# IN Google COLAB us this code instead of the HTML line:
'''
import moviepy.editor
moviepy.editor.ipython_display("temperature_animation.mp4")
'''

'''
# Splitting into training and validation
# Calculate split index based on 80% for training
split_index = int(0.8 * train.shape[0])

# Temporally split the training set into new training and validation sets
train_data, val_data = train[:split_index], train[split_index:]

# Print shapes of the resulting datasets
print("train_data shape:", train_data.shape)  # Should be (num_samples, look_back, c, w, h)
print("val_data shape:", val_data.shape)  # Should be (num_samples, c, w, h)
'''

# Create training samples with the specified look-back and look-ahead windows
X, y = create_sample_pairs(train, look_back=look_back, look_ahead=look_ahead, step_size=step_size)

# Define the split index for training and validation (80% training, 20% validation)
split_index = int(0.8 * len(X))

# Split into training and validation sets
X_train, X_val = X[:split_index], X[split_index:]
y_train, y_val = y[:split_index], y[split_index:]

# Print shapes to verify
print("X_train shape:", X_train.shape)  # Expected: (num_samples, look_back, c, w, h)
print("y_train shape:", y_train.shape)  # Expected: (num_samples, c, w, h)
print("X_val shape:", X_val.shape)      # Expected: (num_samples, look_back, c, w, h)
print("y_val shape:", y_val.shape)      # Expected: (num_samples, c, w, h)

X_test, y_test = create_sample_pairs(test, look_back, look_ahead, step_size)

# Print shapes of the resulting datasets
print("X_test shape:", X_test.shape)  # Should be (num_samples, look_back, c, w, h)
print("y_test shape:", y_test.shape)  # Should be (num_samples, c, w, h)

'''
# Create sample pairs for both training and validation sets
X_train, y_train = create_sample_pairs(train_data, look_back, look_ahead, step_size)
X_val, y_val = create_sample_pairs(val_data, look_back, look_ahead, step_size)

# X_train, y_train = create_sample_pairs(train, look_back, look_ahead, step_size)

# Print shapes of the resulting datasets
print("X_train shape:", X_train.shape)  # Should be (num_samples, look_back, c, w, h)
print("y_train shape:", y_train.shape)  # Should be (num_samples, c, w, h)
print("X_val shape:", X_val.shape)  # Should be (num_samples, look_back, c, w, h)
print("y_val shape:", y_val.shape)  # Should be (num_samples, c, w, h)
'''
'''
# Sample selection
random_i = 42  # Select a specific time series sample
look_back_data = X_train[random_i, :, 1, :, :]  # Look-back data (time steps, width, height)

# Set up the figure
fig, ax = plt.subplots(figsize=(8, 6))
img = ax.imshow(look_back_data[0], cmap='coolwarm', vmin=np.nanmin(look_back_data), vmax=np.nanmax(look_back_data))
fig.colorbar(img, ax=ax, label="Temperature")
ax.set_title(f"Temperature Over Time at Sample {random_i}")
ax.set_xlabel("Width")
ax.set_ylabel("Height")

# Animation update function
def update_frame(t):
    img.set_data(look_back_data[t])
    # Update the title to show the current time step
    ax.set_title(f"Temperature at Time Step {t} (6-hour intervals)")

# Create animation
ani = FuncAnimation(fig, update_frame, frames=look_back_data.shape[0], interval=200)

# Save the animation as an HTML5 video
ani.save('temperature_animation.mp4', writer="ffmpeg")

# Display the video in JupyterLab
plt.close(fig)  # Close the figure to avoid extra static plot output
HTML('<video controls src="temperature_animation.mp4" width="80%"></video>')
'''
# IN Google COLAB us this code instead of the HTML line:
'''
import moviepy.editor
moviepy.editor.ipython_display("temperature_animation.mp4")
'''

# Select a sample
random_i = 352
random_w, random_h = 50, 144

# Data for look-back and look-ahead
look_back_data = X_train[random_i, :, :, random_w, random_h]
print("look_back_data shape:", np.shape(look_back_data))
print(look_back_data.shape)
look_ahead_data = y_train[random_i, :, random_w, random_h]
print("look_ahead_data shape:", np.shape(look_ahead_data))
print(look_ahead_data.shape)

# Plot look-back and look-ahead on the same plot
f, ax = plt.subplots(2, figsize=(10, 10))
ax[0].plot(range(len(look_back_data)), look_back_data[:, 0], color='blue', label="Look-back (Temperature)")
ax[0].scatter([len(look_back_data) + look_ahead], look_ahead_data[0], color='orange', label="Look-ahead (Temperature)")

# Add titles and labels
ax[0].set_title("Temperature: Look-back and Look-ahead")
ax[0].set_xlabel("Time Steps (6-hour intervals)")
ax[0].set_ylabel("Temperature")
ax[0].grid(True)
ax[0].legend()

# Plot look-back and look-ahead on the same plot
ax[1].plot(range(len(look_back_data)), look_back_data[:, 1], color='blue', label="Look-back (Salinity)")
ax[1].scatter([len(look_back_data) + look_ahead], look_ahead_data[1], color='orange', label="Look-ahead (Salinity)")

# Add titles and labels
ax[1].set_title("Salinity: Look-back and Look-ahead")
ax[1].set_xlabel("Time Steps (6-hour intervals)")
ax[1].set_ylabel("Salinity")
ax[1].grid(True)
ax[1].legend()

plt.tight_layout()
plt.show()

# Select a sample
random_i = 70
random_w, random_h = 50, 144

# Data for look-back and look-ahead
look_back_data = X_val[random_i, :, :, random_w, random_h]
print("look_back_data shape:", np.shape(look_back_data))
print(look_back_data.shape)
look_ahead_data = y_val[random_i, :, random_w, random_h]
print("look_ahead_data shape:", np.shape(look_ahead_data))
print(look_ahead_data.shape)

# Plot look-back and look-ahead on the same plot
f, ax = plt.subplots(2, figsize=(10, 10))
ax[0].plot(range(len(look_back_data)), look_back_data[:, 0], color='blue', label="Look-back (Temperature)")
ax[0].scatter([len(look_back_data) + look_ahead], look_ahead_data[0], color='orange', label="Look-ahead (Temperature)")

# Add titles and labels
ax[0].set_title("Temperature: Look-back and Look-ahead")
ax[0].set_xlabel("Time Steps (6-hour intervals)")
ax[0].set_ylabel("Temperature")
ax[0].grid(True)
ax[0].legend()

# Plot look-back and look-ahead on the same plot
ax[1].plot(range(len(look_back_data)), look_back_data[:, 1], color='blue', label="Look-back (Salinity)")
ax[1].scatter([len(look_back_data) + look_ahead], look_ahead_data[1], color='orange', label="Look-ahead (Salinity)")

# Add titles and labels
ax[1].set_title("Salinity: Look-back and Look-ahead")
ax[1].set_xlabel("Time Steps (6-hour intervals)")
ax[1].set_ylabel("Salinity")
ax[1].grid(True)
ax[1].legend()

plt.tight_layout()
plt.show()

"""LSTM + CNN combined model"""

'''
X_train = np.nan_to_num(X_train, nan=0.0)
y_train = np.nan_to_num(y_train, nan=0.0)
X_val = np.nan_to_num(X_val, nan=0.0)
y_val = np.nan_to_num(y_val, nan=0.0)
'''

X_train[np.isnan(X_train)] = 0.0
y_train[np.isnan(y_train)] = 0.0
X_val[np.isnan(X_val)] = 0.0
y_val[np.isnan(y_val)] = 0.0

# Print shapes of the resulting datasets
print("X_train shape:", X_train.shape)  # Should be (num_samples, look_back, c, w, h)
print("y_train shape:", y_train.shape)  # Should be (num_samples, c, w, h)
print("X_val shape:", X_val.shape)      # Should be (val_samples, look_back, c, w, h)
print("y_val shape:", y_val.shape)      # Should be (val_samples, c, w, h)

print("NaNs in X_train:", np.isnan(X_train).any())
print("NaNs in y_train:", np.isnan(y_train).any())

print("Infs in X_train:", np.isinf(X_train).any())
print("Infs in y_train:", np.isinf(y_train).any())

print("NaNs in X_val:", np.isnan(X_val).any())
print("NaNs in y_val:", np.isnan(y_val).any())

print("Infs in X_val:", np.isinf(X_val).any())
print("Infs in y_val:", np.isinf(y_val).any())

# Select a sample
random_i = 70
random_w, random_h = 50, 144

# Data for look-back and look-ahead
look_back_data = X_val[random_i, :, :, random_w, random_h]
print("look_back_data shape:", np.shape(look_back_data))
print(look_back_data.shape)
look_ahead_data = y_val[random_i, :, random_w, random_h]
print("look_ahead_data shape:", np.shape(look_ahead_data))
print(look_ahead_data.shape)

# Plot look-back and look-ahead on the same plot
f, ax = plt.subplots(2, figsize=(10, 10))
ax[0].plot(range(len(look_back_data)), look_back_data[:, 0], color='blue', label="Look-back (Temperature)")
ax[0].scatter([len(look_back_data) + look_ahead], look_ahead_data[0], color='orange', label="Look-ahead (Temperature)")

# Add titles and labels
ax[0].set_title("Temperature: Look-back and Look-ahead")
ax[0].set_xlabel("Time Steps (6-hour intervals)")
ax[0].set_ylabel("Temperature")
ax[0].grid(True)
ax[0].legend()

# Plot look-back and look-ahead on the same plot
ax[1].plot(range(len(look_back_data)), look_back_data[:, 1], color='blue', label="Look-back (Salinity)")
ax[1].scatter([len(look_back_data) + look_ahead], look_ahead_data[1], color='orange', label="Look-ahead (Salinity)")

# Add titles and labels
ax[1].set_title("Salinity: Look-back and Look-ahead")
ax[1].set_xlabel("Time Steps (6-hour intervals)")
ax[1].set_ylabel("Salinity")
ax[1].grid(True)
ax[1].legend()

plt.tight_layout()
plt.show()

'''
X_train = X_train[:, :, :, ~mask]
X_val = X_val[:, :, :, ~mask]
y_train = y_train[:, :, ~mask]
y_val = y_val[:, :, ~mask]

# Print shapes of the resulting datasets
print("X_train shape:", X_train.shape)  # Should be (num_samples, look_back, c, w, h)
print("y_train shape:", y_train.shape)  # Should be (num_samples, c, w, h)
print("X_val shape:", X_val.shape)      # Should be (val_samples, look_back, c, w, h)
print("y_val shape:", y_val.shape)      # Should be (val_samples, c, w, h)
'''

# Split y_train and y_val into separate temperature and salinity arrays
y_train_temperature = y_train[:, 0, :, :]  # Select the temperature channel (index 0)
y_train_salinity = y_train[:, 1, :, :]     # Select the salinity channel (index 1)
print("y_train_temperature shape:", y_train_temperature.shape)  # Should be (num_samples, c, w, h)
print("y_train_salinity shape:", y_train_salinity.shape)  # Should be (num_samples, c, w, h)

y_val_temperature = y_val[:, 0, :, :]      # Select the temperature channel (index 0)
y_val_salinity = y_val[:, 1, :, :]         # Select the salinity channel (index 1)
print("y_val_temperature shape:", y_val_temperature.shape)      # Should be (val_samples, c, w, h)
print("y_val_salinity shape:", y_val_salinity.shape)      # Should be (val_samples, c, w, h)

# Input dimensions
time_steps = X_train.shape[1]  # 28
channels = X_train.shape[2]    # 2 (temperature, salinity)
height = X_train.shape[3]      # 111
width = X_train.shape[4]       # 251

# Define the model
input_layer = Input(shape=(time_steps, channels, height, width))

# Apply CNN to each time step
cnn_layer = TimeDistributed(Conv2D(16, (3, 3), activation='relu', padding='same'))(input_layer)
cnn_layer = TimeDistributed(Conv2D(32, (3, 3), activation='relu', padding='same'))(cnn_layer)

# Print the shape after the CNN layer
print("Shape after CNN layers (cnn_layer) before flatten():", cnn_layer.shape)

cnn_layer = TimeDistributed(Flatten())(cnn_layer)  # Flatten spatial dimensions: (time_steps, channels * height * width)

# Print the shape after the CNN layer
print("Shape after CNN layers (cnn_layer) after flatten():", cnn_layer.shape)

# Reshape for LSTM input
reshaped_layer = Reshape((time_steps, -1))(cnn_layer)  # Shape (time_steps, flattened spatial features)

# Print the shape after the CNN layer
print("Shape after CNN layers (cnn_layer):", reshaped_layer.shape)

# Optional: Create a model and print the summary to verify shapes
model = Model(inputs=input_layer, outputs=reshaped_layer)
model.summary()

# LSTM layer for temporal processing
lstm_layer = LSTM(64, return_sequences=False)(reshaped_layer)
print("Shape of LSTM layers:", lstm_layer.shape)

# Separate Dense output layers for temperature and salinity predictions
# Temperature prediction (channel 0)
temperature_output = Dense(height * width, activation='linear')(lstm_layer)
print("Shape of dense layers for temperature:", temperature_output.shape)
temperature_output = Reshape((1, height, width), name='temperature_output')(temperature_output)  # 1 channel for temperature
print("Shape of reshape layers for temperature:", temperature_output.shape)

# Salinity prediction (channel 1)
salinity_output = Dense(height * width, activation='linear')(lstm_layer)
print("Shape of dense layers for salinity:", salinity_output.shape)
salinity_output = Reshape((1, height, width), name='salinity_output')(salinity_output)  # 1 channel for salinity
print("Shape of reshape layers for salinity:", salinity_output.shape)

# Build and compile the model
# model = Model(inputs=input_layer, outputs=output_layer)

model = Model(inputs=input_layer, outputs=[temperature_output, salinity_output])

# Compile the model with two separate losses for temperature and salinity
model.compile(
    optimizer=Adam(learning_rate=0.001),
    loss={'temperature_output': 'mse', 'salinity_output': 'mse'},
    metrics={'temperature_output': 'mae', 'salinity_output': 'mae'}
)

#model.compile(optimizer=Adam(learning_rate=0.001), loss='mse')

# Check output names
print("Model output names:", model.output_names)

'''
# Dense output layer to predict temperature and salinity
output_layer = Dense(channels * height * width, activation='linear')(lstm_layer)
print("Shape of output layers:", output_layer.shape)

output_layer = Reshape((channels, height, width))(output_layer)
print("Shape of output layers:", output_layer.shape)
'''

# Train the model
# history = model.fit(X_train, y_train, epochs=10, batch_size=8, validation_data=(X_val, y_val))

# Train the model with separate validation data for each output
'''
history = model.fit(
    X_train,
    {'temperature_output': y_train_temperature, 'salinity_output': y_train_salinity},
    epochs=10,
    batch_size=8,
    validation_data=(X_val, {'temperature_output': y_val_temperature, 'salinity_output': y_val_salinity})
)
'''

# Define EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss',  # monitor validation loss
                               patience=10,  # number of epochs with no improvement before stopping
                               restore_best_weights=True,  # restore model weights from the best epoch
                               verbose=1)  # print out details of early stopping

history = model.fit(
    X_train,
    [y_train_temperature, y_train_salinity],  # for multiple outputs
    epochs=100,  # the number of epochs to train
    batch_size=1,  # batch size for training
    validation_data=(X_val, [y_val_temperature, y_val_salinity]),  # for multiple outputs
    verbose=2,  # Shows more detailed logs
    callbacks=[early_stopping],  # Add EarlyStopping callback
)

'''
class DataGenerator(tf.keras.utils.Sequence):
    def __init__(self, X_data, y_data_temperature, y_data_salinity, batch_size, shuffle=True, **kwargs):
        # Call the parent class constructor with the extra arguments
        super().__init__(**kwargs)  # This will ensure proper handling of additional args
        self.X_data = X_data
        self.y_data_temperature = y_data_temperature
        self.y_data_salinity = y_data_salinity
        self.batch_size = batch_size
        self.shuffle = shuffle
        self.indices = np.arange(len(self.X_data))
        if self.shuffle:
            np.random.shuffle(self.indices)

    def __len__(self):
        # The number of batches per epoch
        return int(np.floor(len(self.X_data) / self.batch_size))

    def on_epoch_end(self):
        if self.shuffle:
            np.random.shuffle(self.indices)

    def __getitem__(self, index):
        # Get the indices for the current batch
        batch_indices = self.indices[index * self.batch_size: (index + 1) * self.batch_size]

        # Create batches
        X_batch = self.X_data[batch_indices]
        y_batch_temperature = self.y_data_temperature[batch_indices]
        y_batch_salinity = self.y_data_salinity[batch_indices]

        # Return outputs as a tuple, not a list
        return X_batch, (y_batch_temperature, y_batch_salinity)


# Create training and validation data generators
train_generator = DataGenerator(X_train, y_train_temperature, y_train_salinity, batch_size=8)
val_generator = DataGenerator(X_val, y_val_temperature, y_val_salinity, batch_size=8)

# Define EarlyStopping callback
early_stopping = EarlyStopping(monitor='val_loss',  # monitor validation loss
                               patience=10,  # number of epochs with no improvement before stopping
                               restore_best_weights=True,  # restore model weights from the best epoch
                               verbose=1)  # print out details of early stopping

# Train the model using the generators
history = model.fit(
    train_generator,
    epochs=100,
    validation_data=val_generator,
    verbose=2,
    callbacks=[early_stopping],
)
'''
# history = model.fit(X_train, [y_train_temperature, y_train_salinity], epochs=10, batch_size=8, validation_data=(X_val, [y_val_temperature, y_val_salinity]))

print(history.history.keys())  # To check what keys are available in the history

print(X_train.shape)
print(y_train_temperature.shape)
print(y_train_salinity.shape)
print(X_val.shape)
print(y_val_temperature.shape)
print(y_val_salinity.shape)

print("NaNs in X_train:", np.isnan(X_train).any())
print("NaNs in y_train:", np.isnan(y_train_temperature).any())
print("NaNs in y_train:", np.isnan(y_train_salinity).any())
print("Infs in X_train:", np.isinf(X_train).any())
print("Infs in y_train:", np.isinf(y_train_temperature).any())
print("Infs in y_train:", np.isinf(y_train_salinity).any())

print("NaNs in X_val:", np.isnan(X_val).any())
print("NaNs in y_val:", np.isnan(y_val_temperature).any())
print("NaNs in y_val:", np.isnan(y_val_salinity).any())
print("Infs in X_val:", np.isinf(X_val).any())
print("Infs in y_val:", np.isinf(y_val_temperature).any())
print("Infs in y_val:", np.isinf(y_val_salinity).any())

# Use the trained model to predict on the validation data
y_pred = model.predict(X_val)
print("Shape of y_pred:", np.shape(y_pred))

# Print the shape of the predicted output to verify
#print("Predicted Output Shape:", y_pred.shape)

# Print the shape of the predicted output to verify
# y_pred will now be a list with two elements: one for temperature and one for salinity
temperature_pred = y_pred[0]  # Predicted temperature (first output)
salinity_pred = y_pred[1]    # Predicted salinity (second output)

# Print the shape of predictions
print("Shape of Predicted Temperature:", temperature_pred.shape)
print("Shape of Predicted Salinity:", salinity_pred.shape)

# Flatten the predictions and true values to make them compatible for RMSE and R² calculation
temperature_pred_flat = temperature_pred.flatten()
salinity_pred_flat = salinity_pred.flatten()

y_val_temperature_flat = y_val_temperature.flatten()
y_val_salinity_flat = y_val_salinity.flatten()

# Calculate RMSE for temperature and salinity on validation data
rmse_temperature = np.sqrt(mean_squared_error(y_val_temperature_flat, temperature_pred_flat))
rmse_salinity = np.sqrt(mean_squared_error(y_val_salinity_flat, salinity_pred_flat))

# Calculate R² score for temperature and salinity on validation data
r2_temperature = r2_score(y_val_temperature_flat, temperature_pred_flat)
r2_salinity = r2_score(y_val_salinity_flat, salinity_pred_flat)

# Calculate Mean Absolute Percentage Error (MAPE) for temperature and salinity
mape_temperature = mean_absolute_percentage_error(y_val_temperature_flat, temperature_pred_flat)
mape_salinity = mean_absolute_percentage_error(y_val_salinity_flat, salinity_pred_flat)

# Calculate Explained Variance Score for temperature and salinity
explained_variance_temperature = explained_variance_score(y_val_temperature_flat, temperature_pred_flat)
explained_variance_salinity = explained_variance_score(y_val_salinity_flat, salinity_pred_flat)

# Print the RMSE and R² scores
print("RMSE")
print(f"Validation Temperature: {rmse_temperature:.4f}")
print(f"Validation Salinity: {rmse_salinity:.4f}")

print("\nR2 score")
print(f"Validation Temperature: {r2_temperature:.4f}")
print(f"Validation Salinity: {r2_salinity:.4f}")

# Print the MAPE scores
print("\nMAPE (Mean Absolute Percentage Error)")
print(f"Validation Temperature: {mape_temperature:.4f}")
print(f"Validation Salinity: {mape_salinity:.4f}")

# Print the Explained Variance scores
print("\nExplained Variance Score")
print(f"Validation Temperature: {explained_variance_temperature:.4f}")
print(f"Validation Salinity: {explained_variance_salinity:.4f}")

# Evaluate the model
# val_loss = model.evaluate(X_val, y_val)
# print(f"Validation Loss: {val_loss}")

# Evaluate model on validation data and print the total validation loss
val_loss = model.evaluate(X_val, [y_val_temperature, y_val_salinity])
print(f"Total Validation Loss: {val_loss}")

# Evaluate model on training data and print the total training loss
#train_loss = model.evaluate(X_train, [y_train_temperature, y_train_salinity], verbose=1)
#print(f"Total Training Loss: {train_loss}")

import matplotlib.pyplot as plt

# Plot training and validation loss curve
plt.figure(figsize=(10, 6))
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.title('Training and Validation Loss Curve')
plt.legend()
plt.grid(True)
plt.show()

import matplotlib.pyplot as plt

# Plot training and validation MAE for temperature and salinity
plt.figure(figsize=(14, 6))

# Plot Temperature MAE
plt.subplot(1, 2, 1)
plt.plot(history.history['temperature_output_mae'], label='Training Temperature MAE')
plt.plot(history.history['val_temperature_output_mae'], label='Validation Temperature MAE')
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Temperature MAE Over Epochs')
plt.legend()
plt.grid()

# Plot Salinity MAE
plt.subplot(1, 2, 2)
plt.plot(history.history['salinity_output_mae'], label='Training Salinity MAE')
plt.plot(history.history['val_salinity_output_mae'], label='Validation Salinity MAE')
plt.xlabel('Epochs')
plt.ylabel('Mean Absolute Error (MAE)')
plt.title('Salinity MAE Over Epochs')
plt.legend()
plt.grid()

plt.tight_layout()
plt.show()

# Select a sample index to visualize (e.g., the first sample)
sample_index = 42

# Extract the true and predicted temperature and salinity for the chosen sample
temperature_true = y_val[sample_index, 0, :, :]  # True temperature for selected sample
salinity_true = y_val[sample_index, 1, :, :]     # True salinity for selected sample

temperature_pred = y_pred[0][sample_index, 0, :, :]  # Predicted temperature
salinity_pred = y_pred[1][sample_index, 0, :, :]     # Predicted salinity

plt.figure(figsize=(12, 6))

# True Temperature
plt.subplot(2, 2, 1)
plt.imshow(temperature_true, cmap='coolwarm', interpolation='nearest')
plt.title("True Temperature")
plt.colorbar()

# Predicted Temperature
plt.subplot(2, 2, 2)
plt.imshow(temperature_pred, cmap='coolwarm', interpolation='nearest')
plt.title("Predicted Temperature")
plt.colorbar()

# True Salinity
plt.subplot(2, 2, 3)
plt.imshow(salinity_true, cmap='viridis', interpolation='nearest')
plt.title("True Salinity")
plt.colorbar()

# Predicted Salinity
plt.subplot(2, 2, 4)
plt.imshow(salinity_pred, cmap='viridis', interpolation='nearest')
plt.title("Predicted Salinity")
plt.colorbar()

plt.tight_layout()
plt.show()

# Select a sample index to visualize (e.g., the 56th sample)
sample_index = 55

# Extract the true temperature and salinity for the chosen sample
temperature_true = y_val[sample_index, 0, :, :]  # True temperature for selected sample
salinity_true = y_val[sample_index, 1, :, :]    # True salinity for selected sample

# Extract the predicted temperature and salinity for the chosen sample
temperature_pred = np.squeeze(y_pred[0][sample_index, :, :])  # Predicted temperature for selected sample
salinity_pred = np.squeeze(y_pred[1][sample_index, :, :])     # Predicted salinity for selected sample

# Create a figure to visualize the true and predicted temperature and salinity for the selected sample
plt.figure(figsize=(12, 6))

# True Temperature
plt.subplot(2, 2, 1)
plt.imshow(temperature_true, cmap='coolwarm', interpolation='nearest')
plt.title(f"True Temperature - Sample {sample_index + 1}")
plt.colorbar()

# Predicted Temperature
plt.subplot(2, 2, 2)
plt.imshow(temperature_pred, cmap='coolwarm', interpolation='nearest')
plt.title(f"Predicted Temperature - Sample {sample_index + 1}")
plt.colorbar()

# True Salinity
plt.subplot(2, 2, 3)
plt.imshow(salinity_true, cmap='viridis', interpolation='nearest')
plt.title(f"True Salinity - Sample {sample_index + 1}")
plt.colorbar()

# Predicted Salinity
plt.subplot(2, 2, 4)
plt.imshow(salinity_pred, cmap='viridis', interpolation='nearest')
plt.title(f"Predicted Salinity - Sample {sample_index + 1}")
plt.colorbar()

plt.tight_layout()
plt.show()

'''
# Select a sample index to visualize (e.g., the 36th sample)
sample_index = 36

# Extract the input data (28 time steps for a sample) from X_val (temperature channel)
X_sample = X_val[sample_index, :, 0, :, :]  # Select the temperature channel (first channel)
X_sample = X_sample.mean(axis=(1, 2))  # Average over spatial dimensions (w, h) to get a 28-time steps sequence

# Extract the true labels (future values) from y_val (temperature and salinity)
y_true_temperature = y_val[sample_index, 0, :, :]
y_true_temperature = y_true_temperature.mean()  # Average over spatial dimensions (w, h)

y_true_salinity = y_val[sample_index, 1, :, :]
y_true_salinity = y_true_salinity.mean()  # Average over spatial dimensions (w, h)

# Extract the predicted values (future values) from y_pred (temperature and salinity)
y_pred_temperature = y_pred[0, 0, 0, :, :]
y_pred_temperature = y_pred_temperature.mean()  # Average over spatial dimensions (w, h)

y_pred_salinity = y_pred[1, 0, 0, :, :]
y_pred_salinity = y_pred_salinity.mean()  # Average over spatial dimensions (w, h)

# Create the first figure for temperature predictions
plt.figure(figsize=(12, 6))

# Plot the input time series (28 time steps for temperature)
plt.subplot(1, 2, 1)  # Subplot for temperature
plt.plot(np.arange(28), X_sample, label="Input (28 Time Steps)", marker='o', color='blue')
plt.scatter(28, y_true_temperature, label="True Temperature", color='red', zorder=5)
plt.scatter(28, y_pred_temperature, label="Predicted Temperature", color='green', zorder=5)
plt.xlabel('Time Step')
plt.ylabel('Temperature')
plt.title(f"True vs Predicted Temperature for Sample {sample_index}")
plt.legend()

# Create the second figure for salinity predictions
plt.subplot(1, 2, 2)  # Subplot for salinity
plt.plot(np.arange(28), X_sample, label="Input (28 Time Steps)", marker='o', color='blue')
plt.scatter(28, y_true_salinity, label="True Salinity", color='red', zorder=5)
plt.scatter(28, y_pred_salinity, label="Predicted Salinity", color='green', zorder=5)
plt.xlabel('Time Step')
plt.ylabel('Salinity')
plt.title(f"True vs Predicted Salinity for Sample {sample_index}")
plt.legend()

plt.tight_layout()
plt.show()
'''

print("y_pred shape:", np.shape(y_pred))

# First, transpose the dimensions to bring the 77 samples to the first axis
y_pred = np.transpose(y_pred, (1, 0, 2, 3, 4))

# Then, squeeze out the singleton dimension (1) in the third axis
y_pred = np.squeeze(y_pred, axis=2)

# The resulting shape will be (77, 2, 111, 251)
print("y_pred shape:", y_pred.shape)

# Select a sample
random_i = 70
random_w, random_h = 50, 144

# Data for look-back and look-ahead
look_back_data = X_val[random_i, :, :, random_w, random_h]
print("look_back_data shape:", np.shape(look_back_data))
print(look_back_data.shape)
look_ahead_data = y_val[random_i, :, random_w, random_h]
print("look_ahead_data shape:", np.shape(look_ahead_data))
print(look_ahead_data.shape)

# Plot look-back and look-ahead on the same plot
f, ax = plt.subplots(2, figsize=(10, 10))
ax[0].plot(range(len(look_back_data)), look_back_data[:, 0], color='blue', label="Look-back (Temperature)")
ax[0].scatter([len(look_back_data) + look_ahead], look_ahead_data[0], color='orange', label="Look-ahead (Temperature)")

# Add titles and labels
ax[0].set_title("Temperature: Look-back and Look-ahead")
ax[0].set_xlabel("Time Steps (6-hour intervals)")
ax[0].set_ylabel("Temperature")
ax[0].grid(True)
ax[0].legend()

# Plot look-back and look-ahead on the same plot
ax[1].plot(range(len(look_back_data)), look_back_data[:, 1], color='blue', label="Look-back (Salinity)")
ax[1].scatter([len(look_back_data) + look_ahead], look_ahead_data[1], color='orange', label="Look-ahead (Salinity)")

# Add titles and labels
ax[1].set_title("Salinity: Look-back and Look-ahead")
ax[1].set_xlabel("Time Steps (6-hour intervals)")
ax[1].set_ylabel("Salinity")
ax[1].grid(True)
ax[1].legend()

plt.tight_layout()
plt.show()

# Select a random sample index and spatial location
random_i = 70
random_w, random_h = 50, 144

print("X_val shape:", X_val.shape)
print("y_val shape:", y_val.shape)

# Data for look-back (28 time steps) and look-ahead (next time step)
look_back_data = X_val[random_i, :, :, random_w, random_h]  # Shape: (28, 2) -> (time steps, temperature + salinity)
print("look_back_data shape:", np.shape(look_back_data))   #(28, 2)
look_ahead_data_true = y_val[random_i, :, random_w, random_h]  # Shape: (2) -> temperature and salinity
print("look_ahead_data shape:",np.shape(look_ahead_data_true))  #(2,)

# Assuming y_pred is a numpy array of predictions with shape (batch_size, time_steps, c, w, h)
# Select the predicted data from y_pred (taking the last time step)
look_ahead_data_pred = y_pred[random_i, :, random_w, random_h]  # Taking the predicted values for temperature and salinity

# Plot look-back and look-ahead on the same plot
f, ax = plt.subplots(2, figsize=(10, 10))

# Plot Temperature: Look-back and Look-ahead for True Values
ax[0].plot(range(len(look_back_data)), look_back_data[:, 0], color='blue', label="Look-back (Temperature)")
ax[0].scatter([len(look_back_data) + look_ahead], look_ahead_data_true[0], color='orange', label="True Look-ahead (Temperature)")

# Plot Temperature: Look-back and Look-ahead for Predicted Values
ax[0].scatter([len(look_back_data) + look_ahead], look_ahead_data_pred[0], color='green', label="Predicted Look-ahead (Temperature)")

# Add titles and labels for Temperature
ax[0].set_title("Temperature: Look-back and Look-ahead (True vs Predicted)")
ax[0].set_xlabel("Time Steps (6-hour intervals)")
ax[0].set_ylabel("Temperature")
ax[0].grid(True)
ax[0].legend()

# Plot Salinity: Look-back and Look-ahead for True Values
ax[1].plot(range(len(look_back_data)), look_back_data[:, 1], color='blue', label="Look-back (Salinity)")
ax[1].scatter([len(look_back_data) + look_ahead], look_ahead_data_true[1], color='orange', label="True Look-ahead (Salinity)")

# Plot Salinity: Look-back and Look-ahead for Predicted Values
ax[1].scatter([len(look_back_data) + look_ahead], look_ahead_data_pred[1], color='green', label="Predicted Look-ahead (Salinity)")

# Add titles and labels for Salinity
ax[1].set_title("Salinity: Look-back and Look-ahead (True vs Predicted)")
ax[1].set_xlabel("Time Steps (6-hour intervals)")
ax[1].set_ylabel("Salinity")
ax[1].grid(True)
ax[1].legend()

# Display the plot
plt.tight_layout()
plt.show()

batch_size = 8

# Use the trained model to predict on the training data       #####when GPU is used
temperature_train_pred = []
salinity_train_pred = []

for i in range(0, len(X_train), batch_size):
    if i + batch_size > len(X_train):
        batch = X_train[i:]
    else:
        batch = X_train[i:i + batch_size]

    y_train_pred_batch = model.predict(batch)

    # Append each type of prediction separately
    temperature_train_pred.append(y_train_pred_batch[0])  # Temperature predictions
    salinity_train_pred.append(y_train_pred_batch[1])     # Salinity predictions

# Concatenate lists along the first axis (batch dimension)
temperature_train_pred = np.concatenate(temperature_train_pred, axis=0)
salinity_train_pred = np.concatenate(salinity_train_pred, axis=0)

# Print the shape of predictions for training data
print("Shape of Predicted Training Temperature:", temperature_train_pred.shape)
print("Shape of Predicted Training Salinity:", salinity_train_pred.shape)

# Flatten the predictions and true values for RMSE and R² calculation
temperature_train_pred_flat = temperature_train_pred.flatten()
salinity_train_pred_flat = salinity_train_pred.flatten()

y_train_temperature_flat = y_train_temperature.flatten()
y_train_salinity_flat = y_train_salinity.flatten()

# Calculate RMSE for temperature and salinity on training data
rmse_train_temperature = np.sqrt(mean_squared_error(y_train_temperature_flat, temperature_train_pred_flat))
rmse_train_salinity = np.sqrt(mean_squared_error(y_train_salinity_flat, salinity_train_pred_flat))

# Calculate R² score for temperature and salinity on training data
r2_train_temperature = r2_score(y_train_temperature_flat, temperature_train_pred_flat)
r2_train_salinity = r2_score(y_train_salinity_flat, salinity_train_pred_flat)

# Calculate MAPE for temperature and salinity on training data
mape_train_temperature = mean_absolute_percentage_error(y_train_temperature_flat, temperature_train_pred_flat)
mape_train_salinity = mean_absolute_percentage_error(y_train_salinity_flat, salinity_train_pred_flat)

# Calculate Explained Variance Score for temperature and salinity on training data
explained_variance_train_temperature = explained_variance_score(y_train_temperature_flat, temperature_train_pred_flat)
explained_variance_train_salinity = explained_variance_score(y_train_salinity_flat, salinity_train_pred_flat)

# Print the RMSE and R² scores
print("RMSE (Training Data)")
print(f"Training Temperature: {rmse_train_temperature:.4f}")
print(f"Training Salinity: {rmse_train_salinity:.4f}")

print("\nR2 score (Training Data)")
print(f"Training Temperature: {r2_train_temperature:.4f}")
print(f"Training Salinity: {r2_train_salinity:.4f}")

# Print the MAPE scores
print("\nMAPE (Mean Absolute Percentage Error) (Training Data)")
print(f"Training Temperature: {mape_train_temperature:.4f}")
print(f"Training Salinity: {mape_train_salinity:.4f}")

# Print the Explained Variance scores
print("\nExplained Variance Score (Training Data)")
print(f"Training Temperature: {explained_variance_train_temperature:.4f}")
print(f"Training Salinity: {explained_variance_train_salinity:.4f}")

# Select a sample index to visualize (e.g., the first sample)
sample_index = 42

# Convert predictions to NumPy arrays if they are lists
temperature_train_pred = np.array(temperature_train_pred)
salinity_train_pred = np.array(salinity_train_pred)

# Extract the true and predicted temperature and salinity for the chosen sample in the training data
temperature_train_true = y_train[sample_index, 0, :, :]  # True temperature for selected sample
salinity_train_true = y_train[sample_index, 1, :, :]     # True salinity for selected sample

# Remove the extra dimension by using squeeze or by indexing
temperature_train_pred_sample = temperature_train_pred[sample_index, 0, :, :].squeeze()
salinity_train_pred_sample = salinity_train_pred[sample_index, 0, :, :].squeeze()

# Visualization for Training Data
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

# True Temperature (Training Data)
plt.subplot(2, 2, 1)
plt.imshow(temperature_train_true, cmap='coolwarm', interpolation='nearest')
plt.title("True Temperature (Training)")
plt.colorbar()

# Predicted Temperature (Training Data)
plt.subplot(2, 2, 2)
plt.imshow(temperature_train_pred_sample, cmap='coolwarm', interpolation='nearest')
plt.title("Predicted Temperature (Training)")
plt.colorbar()

# True Salinity (Training Data)
plt.subplot(2, 2, 3)
plt.imshow(salinity_train_true, cmap='viridis', interpolation='nearest')
plt.title("True Salinity (Training)")
plt.colorbar()

# Predicted Salinity (Training Data)
plt.subplot(2, 2, 4)
plt.imshow(salinity_train_pred_sample, cmap='viridis', interpolation='nearest')
plt.title("Predicted Salinity (Training)")
plt.colorbar()

plt.tight_layout()
plt.show()

# Select a sample index to visualize (e.g., the first sample)
sample_index = 52

# Convert predictions to NumPy arrays if they are lists
temperature_train_pred = np.array(temperature_train_pred)
salinity_train_pred = np.array(salinity_train_pred)

# Extract the true and predicted temperature and salinity for the chosen sample in the training data
temperature_train_true = y_train[sample_index, 0, :, :]  # True temperature for selected sample
salinity_train_true = y_train[sample_index, 1, :, :]     # True salinity for selected sample

# Remove the extra dimension by using squeeze or by indexing
temperature_train_pred_sample = temperature_train_pred[sample_index, 0, :, :].squeeze()
salinity_train_pred_sample = salinity_train_pred[sample_index, 0, :, :].squeeze()

# Visualization for Training Data
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

# True Temperature (Training Data)
plt.subplot(2, 2, 1)
plt.imshow(temperature_train_true, cmap='coolwarm', interpolation='nearest')
plt.title("True Temperature (Training)")
plt.colorbar()

# Predicted Temperature (Training Data)
plt.subplot(2, 2, 2)
plt.imshow(temperature_train_pred_sample, cmap='coolwarm', interpolation='nearest')
plt.title("Predicted Temperature (Training)")
plt.colorbar()

# True Salinity (Training Data)
plt.subplot(2, 2, 3)
plt.imshow(salinity_train_true, cmap='viridis', interpolation='nearest')
plt.title("True Salinity (Training)")
plt.colorbar()

# Predicted Salinity (Training Data)
plt.subplot(2, 2, 4)
plt.imshow(salinity_train_pred_sample, cmap='viridis', interpolation='nearest')
plt.title("Predicted Salinity (Training)")
plt.colorbar()

plt.tight_layout()
plt.show()

'''
# After training, get the predictions on the training data
y_train_pred = model.predict(X_train)

# Extract the temperature and salinity predictions
y_train_pred_temperature = y_train_pred[0]  # Predicted temperature (first output)
y_train_pred_salinity = y_train_pred[1]    # Predicted salinity (second output)

# Flatten the predictions and true values to make them compatible for RMSE and R² calculation
y_train_pred_temperature_flat = y_train_pred_temperature.flatten()
y_train_pred_salinity_flat = y_train_pred_salinity.flatten()

y_train_temperature_flat = y_train_temperature.flatten()
y_train_salinity_flat = y_train_salinity.flatten()

# Calculate RMSE for temperature and salinity on training data
rmse_temperature = np.sqrt(mean_squared_error(y_train_temperature_flat, y_train_pred_temperature_flat))
rmse_salinity = np.sqrt(mean_squared_error(y_train_salinity_flat, y_train_pred_salinity_flat))

# Calculate R² score for temperature and salinity on training data
r2_temperature = r2_score(y_train_temperature_flat, y_train_pred_temperature_flat)
r2_salinity = r2_score(y_train_salinity_flat, y_train_pred_salinity_flat)

# Print the results
print("RMSE")
print(f"Training Temperature: {rmse_temperature:.4f}")
print(f"Training Salinity: {rmse_salinity:.4f}")

print("\nR2 score")
print(f"Training Temperature: {r2_temperature:.4f}")
print(f"Training Salinity: {r2_salinity:.4f}")


# Select a sample index to visualize (e.g., the first sample)
sample_index = 0

# Extract the true and predicted temperature and salinity for the chosen sample in the training data
temperature_train_true = y_train[sample_index, 0, :, :]  # True temperature for selected sample
salinity_train_true = y_train[sample_index, 1, :, :]     # True salinity for selected sample

temperature_train_pred_sample = y_train_pred[0][sample_index, 0, :, :]  # Predicted temperature
salinity_train_pred_sample = y_train_pred[1][sample_index, 0, :, :]     # Predicted salinity

# Visualization for Training Data
import matplotlib.pyplot as plt

plt.figure(figsize=(12, 6))

# True Temperature (Training Data)
plt.subplot(2, 2, 1)
plt.imshow(temperature_train_true, cmap='coolwarm', interpolation='nearest')
plt.title("True Temperature (Training)")
plt.colorbar()

# Predicted Temperature (Training Data)
plt.subplot(2, 2, 2)
plt.imshow(temperature_train_pred_sample, cmap='coolwarm', interpolation='nearest')
plt.title("Predicted Temperature (Training)")
plt.colorbar()

# True Salinity (Training Data)
plt.subplot(2, 2, 3)
plt.imshow(salinity_train_true, cmap='viridis', interpolation='nearest')
plt.title("True Salinity (Training)")
plt.colorbar()

# Predicted Salinity (Training Data)
plt.subplot(2, 2, 4)
plt.imshow(salinity_train_pred_sample, cmap='viridis', interpolation='nearest')
plt.title("Predicted Salinity (Training)")
plt.colorbar()

plt.tight_layout()
plt.show()
'''